\documentclass[12pt]{article}
\usepackage{geometry}
\geometry{a4paper}
\usepackage[colorlinks, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}
\usepackage[automake]{glossaries-extra}
\usepackage{appendix}
\usepackage{graphicx} % Needed for including images
\usepackage{mdframed} % For creating framed boxes
\usepackage[backend=biber, style=ieee]{biblatex} % Adding biblatex with IEEE style
\usepackage{minted}
\usepackage{array}
\addbibresource{Reference.bib} % Specify the bibliography file, here 'references.bib'


\makeglossaries % Initialize the glossary system

% Define some terms


\newglossaryentry{davinci}{
    name= Da Vinci Platform,
    description={ The da Vinci system is composed of three primary components: the patient-side cart, the surgeon console, and the vision cart. Notably, the da Vinci SP and da Vinci 5 systems stand out for offering seven degree-of-freedom (DOF) through their wristed instruments, whereas the da Vinci Xi system utilizes five DOF. The surgeon console, positioned a short distance away from the operating table, enables the surgeon to manipulate the surgical instruments and camera. The purpose of the vision cart is to provide reliable and intuitive control over the instruments, offer six DOF in terms of dexterity, and deliver immersive three-dimensional (3D) visualization. }
}


\newabbreviation{ots}{OTS}{
      Optical Tracking System}
\newabbreviation{emts}{EMTS}{
      Electromagnetic Tracking System}      
\newabbreviation{rmis}{RMIS}{
      Robot-assisted minimally invasive surgery}
\newabbreviation{pnp}{PnP}{
      Perspective-n-Point}
\newabbreviation{6dof}{6DoF}{
      Six Degrees of Freedom}
\newabbreviation{p3p}{P3P}{
      Perspective-3-Point}
\newabbreviation{epnp}{EPnP}{
      Efficient Perspective-n-Point
}

% Define an acronym




\begin{document}

\begin{titlepage}
      \centering

      \includegraphics[width=0.8\textwidth]{Imperial_College_London_new_logo.png} % Increased width
      \vspace*{1cm}

      \Large
      SURG70006 Group Project

      \large
      2024/10

      \vspace{0.5cm}
      \Huge
      \textbf{Project 19 \\ Surgical Robot Instrument Pose Estimation }

      \vspace{1.3cm}


      % Framed box for student information
      \begin{mdframed}
            \normalsize % Smaller text size within the box
            \textbf{Group Number:} Group 8\\[20pt] % Name on the same line, add vertical space
            \textbf{Group Members:} Jie Li, Jinling Qiu, Leen AIShekh, Yanrui Liu, Yulin Huang\\[20pt] % ID on the same line, add vertical space
            \textbf{Supervisor Name:} Dr Stamatia (Matina) Giannarou % Supervisor on the same line
      \end{mdframed}

      \vspace{2cm} % Adjust space as necessary
      \Large
      \textbf{DEPARTMENT OF}\\
      \vspace{0.1cm} % Adjust line spacing
      \textbf{Surgery and Cancer}

      \vspace{4cm} % Large space as required
      \large
      Imperial College London\\
      


\end{titlepage}

\newpage
\tableofcontents

\newpage

% Introduction & Background
\section{Introduction}
\subsection{Minimally invasive surgery and Robotic surgery}



\subsection{Engineering Background}
\subsubsection{DoF of da Vinci Surgical Robot}
The da Vinci surgical robot operates with \gls{6dof}. These \gls{6dof} refer to the robot's ability to move and rotate in three-dimensional space, including three translational movements (up/down, left/right, forward/backward) and three rotational movements (pitch, yaw, and roll)\cite{app9030546}. This range of motion allows the da Vinci system to replicate the complex dexterity of a surgeon's hand for precise control over surgical instruments in confined spaces.

\subsubsection{Difficulties of Surgical Tools Tracking}
Pose estimation refers to finding the transformation (translation and rotation) that relates the object (or camera) coordinates in 3D space to its projection on a 2D image. The pose estimation of surgical tools has emerged as a critical job in \gls{rmis}. The majority of robots in \gls{rmis} are driven by cables, resulting in kinematic input that is not always precise, since the kinematic data describes the positions of the motor rather than the real position of the joints connected to the motor via a cable\cite{10160287}. 

\subsubsection{Limitations of OTS and EMTS}
\gls{ots} and \gls{emts} are well-established methods for tracking in medical applications. \gls{ots} offers high accuracy but requires a clear line-of-sight, making it prone to errors when obstructed. \gls{emts}, while effective without line-of-sight, suffers from interference caused by metal objects and electronic devices in the operating room, leading to reduced accuracy\cite{8822749}.

\subsubsection{Vision-based Methods}
\begin{enumerate}
      \item \textbf{PnP Problem and Solvers}
      \\\gls{pnp} problem was proposed by Fischler in 1980s, which aims at estimating the position and orientation of a calibrated camera based on known 3D-to-2D point correspondences between a 3D model and their image projections\cite{Fischler1981RandomSC}. The \gls{pnp} is a fundamental problem of many computer vision applications, among which self-motion estimation for robots is a problem of interest.
      \gls{p3p} and \gls{epnp} are two common solutions to the \gls{pnp} problem in camera pose estimation\cite{Lu_2018}. \gls{p3p} calculates the camera pose using a 3D-2D correspondences, which provides up to four possible solutions and can be disambiguated by adding a fourth point. It is suitable for minimal data scenarios. In contrast, \gls{epnp} handles large datasets more efficiently by representing n 3D points as a weighted sum of four virtual control points, reducing computational complexity while maintaining accuracy\cite{10.1007/s11263-008-0152-6}.
      \item \textbf{Marker-based and Marker-less Methods}
      
\end{enumerate}

\subsection{Clinical aspects(TBD)}

\subsection{Problem Statement}
\gls{rmis} has come significantly in the last decade due to advances in surgical robotics such as artificial intelligence and the \gls{davinci}. Pose estimation of surgical instruments has become an important task in \gls{rmis}. 
Nowadays there are many external devices like depth camera, electromagnetic trackers etc. available for space estimation in surgical instruments but they are not practical in in vivo surgeries because of space and hardware constraints\cite{enhancedmarker}. There are some vision-based methods that use external markers to track the instruments. However, these methods have major limitations; the markers must always be visible in the camera's field of view and are sensitive to background changes and occlusions\cite{10160287}. In this case, a vision-based markerless instrument tracking method that does not require any modifications to the hardware setup or external markers is necessary. The main aim of this project is to develop a deep learning based markerless \gls{6dof} surgical instrument pose estimation system. The system will be designed to provide highly accurate surgical instrument \gls{6dof} estimation without relying on external markers or complex hardware.

\begin{figure}[H]
            \centering
            \includegraphics[width=0.8\textwidth]{6Dof.png}
            \caption{\gls{6dof} surgical instrument pose estimation with (left) and without occlusion (right). \cite{surgripe2024}}
      \end{figure}


\section{Related Work}


\section{Proposed Methodlogy}


\section{Goals and Objectives}
\subsection{Objectives of the project}
This project aims to leverage state-of-the-art deep learning models for pose estimation to accurately determine the rotation and position of surgical tools present in the surgical environment during \gls{rmis}. The detailed objectives of the project are as follows:

\begin{enumerate}

\item \textbf{Dataset Analysis}
\\The first objective is to analyze the datasets which include high-quality images captured by the Da Vinci Si endoscopic stereo camera and accurate and consistent ground truth data obtained from the Hamlyn Centre.

\item \textbf{Model Development}
\\Based on the available datasets, we will develop deep learning-based models to detect and estimate the pose of surgical instruments in \gls{rmis}.

\item \textbf{Robust Pose Estimation}
\\We also need to devise novel approaches to ensure accurate and robust pose estimation in the presence of challenges such as partial tool visibility, occlusions, and other variations encountered during surgery. 

\item \textbf{Performance Evaluation}

Finally, the project will evaluate and validate the performance of the applied models under various degrees of occlusion, ensuring their reliability in practical surgical scenarios.

\end{enumerate}


\subsection{Hardware and software requirements(TBD)}



\section{Risk Assessment}
\begin{table}[H]
      \centering
      \renewcommand{\arraystretch}{1.5} 
      \resizebox{\textwidth}{!}{
      \begin{tabular}{| >{\centering\arraybackslash}m{4cm} | >{\centering\arraybackslash}m{5cm} | >{\centering\arraybackslash}m{2.5cm} | >{\centering\arraybackslash}m{2.5cm} |}
      \hline
      \normalsize\textbf{Risk} & \normalsize\textbf{Contingencies} & \normalsize\textbf{Likelihood} & \normalsize\textbf{Impact} \\ 
      \hline
      \normalsize Pose estimation unstable in complex scenes (e.g., occlusion, dynamic background) & \normalsize Optimizing the dataset with more occlusion scene data & \normalsize High & \normalsize Very High \\ 
      \hline
      \normalsize Low Frame Rates & \normalsize Optimizing model efficiency, invest in high-quality hardware & \normalsize High & \normalsize Medium \\ 
      \hline
      \normalsize Model computation time is too long for real-time simulation & \normalsize Optimizing model efficiency and using hardware acceleration & \normalsize High & \normalsize Medium \\ 
      \hline
      \normalsize Reliance on specific deep learning frameworks, leading to migration difficulties & \normalsize Reduced binding to specific frameworks & \normalsize Medium & \normalsize High \\ 
      \hline
      \normalsize Data damage or lost & \normalsize Using GitHub or external storage devices to make backup & \normalsize Medium & \normalsize Very High \\ 
      \hline
      \normalsize Data Privacy & \normalsize Implementing robust data encryption and comply with data protection laws such as GDPR & \normalsize Medium & \normalsize Very High \\ 
      \hline
      \normalsize Ethical and Regulatory & \normalsize Consulting with regulatory experts and following related regulations & \normalsize Very Low & \normalsize High \\ 
      \hline
      \normalsize Timeline delay & \normalsize Making a detailed timeline and a thorough monitoring plan & \normalsize High & \normalsize High \\ 
      \hline
      \end{tabular}
      }
      \caption{Risk Assessment Table}
\end{table}

\section{Project Timeline}

\section{Project Management}
\subsection{Progress Monitoring}
For code part, we use GitHub for monitoring and progress management. We use GitHub's version control to branch the code (each team member manages a branch independently) to ensure smooth team collaboration. We also manually record project logs(such as meeting minutes and group activities) and combine them with timelines to ensure the project run smoothly.

% References (The bibliography will be printed here)
\printbibliography
\printglossaries
\label{sec:glossary}
\end{document}
